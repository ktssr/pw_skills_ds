{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "## What is a parameter?\n",
        "Parameter is setting that control how features are constructed, encoded, or scaled. They play a crucial role in how well your machine learning model performs.\n",
        "\n",
        "## What is correlation?\n",
        "Correlation is a statistical measure that tells us how two variables are related to each other. It shows if increase or decrease in one variable affects the other. Correlation ranges from -1 to 1.\n",
        "\n",
        "## What does negative correlation mean?\n",
        "Negative correlation means when one variable increases the other variable decreases. For example, if hours spent watching TV increases, marks in exam might decrease. The value of correlation in this case will be closer to -1.\n",
        "\n",
        "## Define Machine Learning. What are the main components in Machine Learning?\n",
        "Machine Learning is the process where machines are trained using data to make decisions or predictions without being explicitly programmed. Main components in machine learning are:\n",
        "- Data: Input data is used to train the model.\n",
        "- Model: Algorithm that learns patterns from the data.\n",
        "- Loss function: Measures how good or bad the model is performing.\n",
        "- Optimizer: Used to minimize the loss.\n",
        "- Evaluation metrics: Used to evaluate model performance.\n",
        "\n",
        "## How does loss value help in determining whether the model is good or not?\n",
        "Loss value tells us how far the predicted value is from the actual value. Lower the loss, better the model performance. If loss is high, model is making wrong predictions and needs improvement.\n",
        "\n",
        "## What are continuous and categorical variables?\n",
        "Continuous variables are numerical and can take any value in a range like age, height, weight. Categorical variables are non-numeric and represent categories or labels like gender, country, color.\n",
        "\n",
        "## How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "Categorical variables are converted into numerical form using encoding. Common techniques are:\n",
        "- Label Encoding: Assigns a unique number to each category.\n",
        "- One Hot Encoding: Creates binary columns for each category.\n",
        "\n",
        "## What do you mean by training and testing a dataset?\n",
        "Training dataset is used to train the model. Testing dataset is used to evaluate how well the model performs on new unseen data. This helps in avoiding overfitting.\n",
        "\n",
        "## What is sklearn.preprocessing?\n",
        "`sklearn.preprocessing` is a module in sklearn that provides functions to preprocess the data. This includes functions for scaling, encoding, imputing missing values, etc.\n",
        "\n",
        "## What is a Test set?\n",
        "Test set is a part of dataset which is kept aside and not used during training. It is used to evaluate the performance of the model after training.\n",
        "\n",
        "## How do we split data for model fitting (training and testing) in Python?\n",
        "We can use `train_test_split()` from `sklearn.model_selection` to split data. Example:\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "```\n",
        "\n",
        "## How do you approach a Machine Learning problem?\n",
        "- Understand the problem and data\n",
        "- Clean and preprocess the data\n",
        "- Perform Exploratory Data Analysis (EDA)\n",
        "- Encode and scale the features\n",
        "- Choose and train the model\n",
        "- Evaluate the model using test data\n",
        "- Improve model by tuning hyperparameters\n",
        "\n",
        "## Why do we have to perform EDA before fitting a model to the data?\n",
        "EDA helps in understanding the data, checking missing values, distributions, outliers, and relationships between variables. It helps in making decisions about preprocessing and feature selection.\n",
        "\n",
        "## What is correlation?\n",
        "Correlation is a statistical technique used to measure the strength and direction of relationship between two variables. Positive correlation means both increase together, negative means one increases while other decreases.\n",
        "\n",
        "## What does negative correlation mean?\n",
        "Negative correlation means as one variable increases, the other decreases. It indicates an inverse relationship. Example: number of hours spent partying and exam scores.\n",
        "\n",
        "## How can you find correlation between variables in Python?\n",
        "We can use `.corr()` function in pandas to find correlation. Example:\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "df.corr()\n",
        "```\n",
        "\n",
        "## What is causation? Explain difference between correlation and causation with an example.\n",
        "Causation means one variable directly affects another. Correlation just shows relationship but not cause. Example: Ice cream sales and drowning cases are correlated, but ice cream does not cause drowning. Hot weather causes both.\n",
        "\n",
        "## What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "Optimizer is used to update model weights to minimize loss. Common types:\n",
        "- **SGD (Stochastic Gradient Descent)**: Updates weights using a small batch of data.\n",
        "- **Adam**: Combines momentum and RMSProp. Works well in most cases.\n",
        "\n",
        "Example in TensorFlow:\n",
        "```python\n",
        "import tensorflow as tf\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "```\n",
        "\n",
        "## What is sklearn.linear_model?\n",
        "`sklearn.linear_model` is a module in sklearn which provides linear models like LinearRegression, LogisticRegression, etc. These are used for regression and classification tasks.\n",
        "\n",
        "## What does model.fit() do? What arguments must be given?\n",
        "`model.fit()` trains the model using the training data. It takes the features (X) and target (y) as arguments. Example:\n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "## What does model.predict() do? What arguments must be given?\n",
        "`model.predict()` is used to predict the output for given input data. It takes feature data as argument. Example:\n",
        "```python\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "\n",
        "## What are continuous and categorical variables?\n",
        "Continuous variables are numeric and can take infinite values like 1.5, 3.9, 100. Categorical variables are labels like \"Male\", \"Female\", \"Yes\", \"No\".\n",
        "\n",
        "## What is feature scaling? How does it help in Machine Learning?\n",
        "Feature scaling is a method to normalize the range of independent variables. It helps algorithms that are sensitive to the magnitude of data like KNN, SVM and Gradient Descent. It makes training faster and more accurate.\n",
        "\n",
        "## How do we perform scaling in Python?\n",
        "We can use StandardScaler or MinMaxScaler from `sklearn.preprocessing`. Example:\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "## What is sklearn.preprocessing?\n",
        "`sklearn.preprocessing` is a module which contains functions for preprocessing data before fitting a model. It includes scaling, encoding, normalization, binarization, etc.\n",
        "\n",
        "## How do we split data for model fitting (training and testing) in Python?\n",
        "We use `train_test_split()` from `sklearn.model_selection` to split data into training and test set. Example:\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "```\n",
        "\n",
        "## Explain data encoding?\n",
        "Data encoding is a technique used to convert categorical data into numerical values so that machine learning models can understand it. Common techniques include:\n",
        "- Label Encoding\n",
        "- One Hot Encoding\n"
      ],
      "metadata": {
        "id": "ryyPHTEQT0gx"
      }
    }
  ]
}